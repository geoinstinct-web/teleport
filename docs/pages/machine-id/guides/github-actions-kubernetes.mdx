---
title: Using Machine ID With GitHub Actions and Kubernetes
description: A tutorial for using Machine ID with GitHub Actions and Kubernetes
---

<Details
  title="Version warning"
  opened={true}
  scope={["oss", "enterprise"]}
  scopeOnly={true}
  min="11.0"
>
  Machine ID for GitHub Actions is available starting from Teleport `v11.0`.
</Details>

GitHub Actions is a popular CI/CD platform that works as a part of the larger
GitHub ecosystem.

In this guide, we will use Teleport Machine ID and Kubernetes Access to allow a
GitHub Actions workflow to securely connect to a Kubernetes cluster without the
need for long-lived secrets.

Teleport supports secure joining on both GitHub-hosted and self-hosted GitHub
Actions runners as well as GitHub Enterprise Server.

## Prerequisites

(!docs/pages/includes/edition-prereqs-tabs.mdx!)

- A Kubernetes cluster connected to your Teleport cluster. If you do not already
have one configured, try our
[Kubernetes Access getting started guide.](../../kubernetes-access/getting-started.mdx)
In our examples, this Kubernetes cluster will be named `my-kubernetes-cluster`.
- A local workstation with `tsh` and `tctl` authorized against your Teleport
cluster as a user with the privileges to create configuration resources.
- A GitHub repository with GitHub Actions enabled. This guide uses the example
`gravitational/example`, and this value should be replaced with your own unique
repository.

### 1/4. Create a join token for GitHub Actions

(!docs/pages/includes/machine-id/github-actions-create-token.mdx!)

## Step 2/4. Create a Machine ID bot

With the join token for the GitHub Actions workflow created, we now need to
create a Machine ID bot that the token will grant access to. A Machine ID bot is
a special type of Teleport user designed for access by machines, and can
authenticate using a join token rather than forms of authentication more
suitable to users (e.g such as SSO.)

Before creating the bot, first you must create a role in Teleport which grants
the bot access to your Kubernetes clusters and defines the Kubernetes RBAC
groups that will be added to your bot's requests to the Kubernetes cluster.

Create `role.yaml` and insert the following contents:

```yaml
kind: role
metadata:
  name: github-demo-kube-access
version: v5
spec:
  allow:
    kubernetes_labels:
      # This grants access to any Kubernetes cluster attached to your Teleport
      # cluster.
      '*': '*'
    kubernetes_groups:
      # This states that the `github-demo` group will be applied to your bot's
      # requests to your Kubernetes cluster. In a later step, we will bind this
      # group to a Kubernetes role with a ClusterRoleBinding.
      - github-demo
  deny: {}
```

Apply this to your Teleport cluster:

```code
$ tctl create -f role.yaml
```

Now create the Machine ID bot, assigning it the role you created above:

```code
$ tctl bots add github-demo --roles=github-demo-kube-access --token=github-token
```

## Step 3/4. Configure a Kubernetes Cluster Role Binding

With the bot configured and a Teleport role that will pass a group to
Kubernetes with the bot's requests, you now need a Role Binding to associate a
Kubernetes role to that group.

This is the stage where you will actually determine what level of access the
bot will have when accessing your cluster. In our example, we are applying the
`view` ClusterRole which will allow our bot to read, but not write, all
resources in the Kubernetes cluster.

In your case you may wish to create a custom Kubernetes role that lists the
exact permissions that you want your bot to have. You may also wish to use a
RoleBinding rather than a ClusterRoleBinding to limit the bot's access to an
individual Kubernetes namespace.

Create a file named `clusterolebinding.yaml` and insert:

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: github-demo-group
subjects:
  - kind: Group
    # Note that this name field matches the group name we provided in the
    # Teleport role configuration.
    name: github-demo
    apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  # "view" is a default ClusterRole that grants read-only access to resources
  # See: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
  name: view
  apiGroup: rbac.authorization.k8s.io
```

Apply this to your cluster using `kubectl`:

```
$ kubectl apply -f ./clusterolebinding.yaml
```

## Step 4/4. Create the GitHub Actions workflow

With all the configuration in Teleport and Kubernetes complete, you can now
create a GitHub Actions workflow that can connect to your Kubernetes cluster.

Our example workflow will list all of the pods contained within the cluster,
but this could equally be modified to deploy to a Kubernetes cluster with
`kubectl` or `helm`.

In the GitHub workflows directory of your repository (`.github/workflows/`)
create a new workflow YAML file, in this case `actionstest.yml`.

Insert the following, ensuring that you replace `my-kubernetes-cluster` with the
name of your Kubernetes cluster and `example.domain:443` with the address of
your Teleport Proxy.

```yaml
# This is a basic workflow to help you get started, modify it for your needs.
on:
  push:
    branches:
      - main
jobs:
  demo:
    permissions:
      # The "id-token: write" permission is required or Machine ID will not be 
      # able to authenticate with the cluster.
      id-token: write
      contents: read
    name: guide-demo
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Fetch kubectl
        uses: azure/setup-kubectl@v3
      - name: Fetch Teleport binaries
        uses: teleport-actions/setup@v1
        with:
          version: (=teleport.version=)
      - name: Fetch credentials using Machine ID
        uses: teleport-actions/auth-k8s@v1
        with:
          # Use the address of the auth/proxy server for your own cluster.
          proxy: example.domain:443
          # Use the name of the join token resource you created in step 1.
          token: github-token
          # Use the name of your Kubernetes cluster
          kubernetes-cluster: my-kubernetes-cluster
      - name: List pods
        run: kubectl get pods -A
```

The `auth-k8s` action sets the `KUBECONFIG` for future steps to the credentials
it has fetched from Teleport and this means that most existing tooling for
Kubernetes (e.g `kubectl` and `helm`) will be configured to use your cluster
with no additional configuration.

Add, commit, and push this new workflow file to the `main` branch of your
repository.

Navigate to the **Actions** tab of your GitHub repository in your web browser.
Select the **Workflow** that has now been created and triggered by the change,
and select the `guide-demo` job.

Expand the List pods step of the action, where you can then confirm that the
output shows a list of all the pods within your Kubernetes cluster.

## A note on security implications and risk

Once `teleport-actions/auth-k8s` has been used in a workflow job, all successive
steps in that job will have access to your Kubernetes cluster as your bot. Where
possible, run as few steps as necessary after this action has been used. It may
be a good idea to break your workflow up into multiple jobs in order to
segregate these credentials from other code running in your CI/CD pipeline.

Most importantly, ensure that the role you assign to your GitHub Actions bot has
access to only the resources in your Teleport cluster that your CI/CD needs to
interact with.

## Next steps

You can find out more about the `teleport-action/setup` and
`teleport-actions/auth-k8s` actions on their GitHub repositories:

- [https://github.com/teleport-actions/setup](https://github.com/teleport-actions/setup)
- [https://github.com/teleport-actions/auth-k8s](https://github.com/teleport-actions/auth-k8s)

For more information about GitHub Actions itself, read
[their documentation](https://docs.github.com/en/actions).
